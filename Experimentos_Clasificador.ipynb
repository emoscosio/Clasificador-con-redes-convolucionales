{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experimentos_Clasificador.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEhF68uJ6COo",
        "colab_type": "text"
      },
      "source": [
        "# Experimentos de entrenamiento, validación y test, para la red de clasificación de señales de tráfico. \n",
        "\n",
        "Realizado por Eduardo Moscosio Navarro. \n",
        "\n",
        "Ingeniería Electrónica, Robótica y Mecatrónica. Universidad de Sevilla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhu-T2866TvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linkamos con nuestro Drive para tener disponibles los archivos:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Se instala keras:\n",
        "!pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8dNwiDj6uNy",
        "colab_type": "text"
      },
      "source": [
        "En primer lugar, se cargan todas las librerías que se van a usar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwpJ7sCr8SEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargamos librerías a usar\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator # Para hacer Data Augmentation\n",
        "import shutil # Para copiar a otra carpeta\n",
        "import copy\n",
        "from pathlib import Path # Para crear directorios y saber elementos de una carpeta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVgzOeVL64nG",
        "colab_type": "text"
      },
      "source": [
        "Definición de funciones para preprocesado de imágenes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJCLG9O08kl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funciones:\n",
        "\n",
        "# Cambia a gris y redimensiona al tamaño deseado:\n",
        "def image_gray_resize(images, width = None, height = None, inter = cv2.INTER_AREA):\n",
        "    dim = (width,height)\n",
        "    for k in range(0, len(images)):\n",
        "      # RGB to Gray image conversion\n",
        "      gray = cv2.cvtColor(images[k], cv2.COLOR_BGR2GRAY)\n",
        "      # resize the image\n",
        "      images[k] = cv2.resize(gray, dim, interpolation = inter)\n",
        "      # return the resized image\n",
        "    return 0\n",
        "\n",
        "# Normaliza la imagen:\n",
        "def image_normalize(images, coef = None):\n",
        "    for k in range(0, len(images)):\n",
        "      images[k].astype('float32') # Convierte a float32\n",
        "      images[k] = images[k]/coef # Escalado\n",
        "    return 0\n",
        "\n",
        "# Muestra las imágenes: Esto es porque al convertir a Gray la imagen RGB,\n",
        "# no la muestra directamente gris sino en tonalidades azules, porque no la \n",
        "# interpreta como tal, por eso, se reconvierte a 3 canales, de modo que ya si\n",
        "# se vea. solo se usa para representar\n",
        "def show_im(img):\n",
        "    imagen = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(imagen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V6vadDHL93i",
        "colab_type": "text"
      },
      "source": [
        "Se cargan las imágenes del dataset guardadas como arrays de numpy con anterioridad. Para ello, hay que poner en cada uno la dirección en la que se encuentra esa parte del dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fvRJudR-IY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_lab = np.load('/content/drive/My Drive/matrix_dataset_v2/backup_label_train.npy', allow_pickle=True) # Etiquetas de entrenamiento\n",
        "train_im = np.load('/content/drive/My Drive/matrix_dataset_v2/backup_train.npy', allow_pickle=True) # Imágenes de entrenamiento\n",
        "valid_lab = np.load('/content/drive/My Drive/matrix_dataset_v2/backup_label_valid.npy', allow_pickle=True) # Etiquetas de validación\n",
        "valid_im = np.load('/content/drive/My Drive/matrix_dataset_v2/backup_valid.npy', allow_pickle=True) # Imágenes de validación\n",
        "test_lab = np.load('/content/drive/My Drive/matrix_dataset_v2/backup_label_test.npy', allow_pickle=True) # Etiquetas de test\n",
        "test_im = np.load('/content/drive/My Drive/matrix_dataset_v2/backup_test.npy', allow_pickle=True) # Imágenes de test\n",
        "\n",
        "# Imprime en pantalla el número de imágenes de cada parte\n",
        "print(\"Total de imágenes: \", len(train_lab)+len(valid_lab)+len(test_lab))\n",
        "print(\"Imágenes de Training: \", len(train_lab))\n",
        "print(\"Imágenes de Validation: \", len(valid_lab))\n",
        "print(\"Imágenes de Test: \", len(test_lab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0y1HEgw9BA2",
        "colab_type": "text"
      },
      "source": [
        "Visualización de una imagen de cada clase para ver que todo está correcto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtDoEevS_UNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TRAIN:\")\n",
        "print(\"etiquetas: \", len(train_lab), \"// imagenes: \", len(train_im))\n",
        "print(\"Etiqueta del ejemplo: \", train_lab[100])\n",
        "plt.figure()\n",
        "plt.imshow(train_im[100])\n",
        "\n",
        "\n",
        "print(\"VALIDATION:\")\n",
        "print(\"etiquetas: \", len(valid_lab), \"// imagenes: \", len(valid_im))\n",
        "print(\"Etiqueta del ejemplo: \", valid_lab[500])\n",
        "plt.figure()\n",
        "plt.imshow(valid_im[500])\n",
        "\n",
        "\n",
        "print(\"TEST:\")\n",
        "print(\"etiquetas: \", len(test_lab), \"// imagenes: \", len(test_im))\n",
        "print(\"Etiqueta del ejemplo: \", test_lab[1000])\n",
        "plt.figure()\n",
        "plt.imshow(test_im[1000])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbMX6vJg9HGo",
        "colab_type": "text"
      },
      "source": [
        "Se preprocesa la imagen, empezando con un cambio a escala de grises y luego una redimensión al tamaño deseado, en este caso, 64x64 píxeles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvRds6sjBRgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ancho = 64\n",
        "alto = 64\n",
        "image_gray_resize(train_im, width = ancho, height = alto)\n",
        "image_gray_resize(valid_im, width = ancho, height = alto)\n",
        "image_gray_resize(test_im, width = ancho, height = alto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ziHeQ-OE9bW4"
      },
      "source": [
        "Visualización de una imagen de cada clase para ver que todo está correcto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3hY9kWqB5-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TRAIN:\")\n",
        "print(\"etiquetas: \", len(train_lab), \"// imagenes: \", len(train_im))\n",
        "print(\"Etiqueta del ejemplo: \", train_lab[100])\n",
        "print(\"Tamaño del ejemplo: \", train_im[100].shape)\n",
        "plt.figure()\n",
        "show_im(train_im[100])\n",
        "\n",
        "print(\"VALIDATION:\")\n",
        "print(\"etiquetas: \", len(valid_lab), \"// imagenes: \", len(valid_im))\n",
        "print(\"Etiqueta del ejemplo: \", valid_lab[500])\n",
        "print(\"Tamaño del ejemplo: \", valid_im[500].shape)\n",
        "plt.figure()\n",
        "show_im(valid_im[500])\n",
        "\n",
        "print(\"TEST:\")\n",
        "print(\"etiquetas: \", len(test_lab), \"// imagenes: \", len(test_im))\n",
        "print(\"Etiqueta del ejemplo: \", test_lab[1000])\n",
        "print(\"Tamaño del ejemplo: \", test_im[1000].shape)\n",
        "plt.figure()\n",
        "show_im(test_im[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIDR1vh_9dSh",
        "colab_type": "text"
      },
      "source": [
        "Normalización de las imágenes en un rango de 0 a 1 para que sea procesable por la red. Originalmente están en un rango de 0 a 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqjSfSUhCs1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_normalize(train_im, coef = 255)\n",
        "image_normalize(valid_im, coef = 255)\n",
        "image_normalize(test_im, coef = 255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IABFwE4q9peC"
      },
      "source": [
        "Visualización de una imagen de cada clase para ver que todo está correcto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dph3fAZLE3ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TRAIN:\")\n",
        "print(\"etiquetas: \", len(train_lab), \"// imagenes: \", len(train_im))\n",
        "print(\"Etiqueta del ejemplo: \", train_lab[100])\n",
        "print(\"Tamaño del ejemplo: \", train_im[100].shape)\n",
        "print(train_im[100])\n",
        "\n",
        "print(\"VALIDATION:\")\n",
        "print(\"etiquetas: \", len(valid_lab), \"// imagenes: \", len(valid_im))\n",
        "print(\"Etiqueta del ejemplo: \", valid_lab[500])\n",
        "print(\"Tamaño del ejemplo: \", valid_im[500].shape)\n",
        "print(valid_im[500])\n",
        "\n",
        "print(\"TEST:\")\n",
        "print(\"etiquetas: \", len(test_lab), \"// imagenes: \", len(test_im))\n",
        "print(\"Etiqueta del ejemplo: \", test_lab[1000])\n",
        "print(\"Tamaño del ejemplo: \", test_im[1000].shape)\n",
        "print(test_im[1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2jRGlUf9s2P",
        "colab_type": "text"
      },
      "source": [
        "Por último, se redimensionan las imágenes como un tensor de la forma [-1, alto, ancho, 1] para que la red pueda adquirir los datos a la entrada. Además, se pasan las etiquetas a codificación \"one-hot\", ya que se usará más adelante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWzb8l-2FS9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Primero se pasa cada imagen a una lista de train, valid y test:\n",
        "train_list = []\n",
        "for k in range(0,len(train_im)):\n",
        "  train_list.append(train_im[k])\n",
        "valid_list = []\n",
        "for k in range(0,len(valid_im)):\n",
        "  valid_list.append(valid_im[k])\n",
        "test_list = []\n",
        "for k in range(0,len(test_im)):\n",
        "  test_list.append(test_im[k])\n",
        "\n",
        "# Una vez se tienen las listas, ya se puede redimensionar de la manera deseada\n",
        "# (Si se hacía directamente con los vectores daba un error y no se podía redimensionar)\n",
        "new_train = np.array(train_list)\n",
        "new_validation = np.array(valid_list)\n",
        "new_train = new_train.reshape([-1,alto, ancho,1])\n",
        "new_validation = new_validation.reshape([-1,alto, ancho,1])\n",
        "test = np.array(test_list)\n",
        "test = test.reshape([-1,alto, ancho,1])\n",
        "\n",
        "# Por último, se pasan las etiquetas a categorical para el entrenamiento:\n",
        "# Pasamos las etiquetas a codificación \"one-hot\",es decir, se pone '1' en la posición de clase mientras\n",
        "# las demás se ponen a '0':\n",
        "from keras.utils import to_categorical\n",
        "train_lab = to_categorical(train_lab)\n",
        "valid_lab = to_categorical(valid_lab)\n",
        "test_labels = to_categorical(test_lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aes0GoRBGnin",
        "colab_type": "text"
      },
      "source": [
        "EMPIEZA EL DISEÑO DE LA RED:\n",
        "\n",
        "A continuación hay 3 celdas cada una con un modelo declarado para un experimento concreto. En primer lugar, se encuentran los experimentos con la red original sin ningñun añadido. A continuación, en la celda siguiente, se encuentran los modelos para los experimentos realizados con dropout. Y finalmente, se encuentra la celda con los experimentos realizados para ver el efecto de modificar la red original en la obtención de resultados. Hay que ejecutar cada una y elegir en dicha celda el modelo deseado según el experimento que se quiera hacer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olm4G_aW_Xag",
        "colab_type": "text"
      },
      "source": [
        "PRIMEROS EXPERIMENTOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JuRD_8_A_4hA",
        "colab": {}
      },
      "source": [
        "############# Código principal de red convolucional ####################################\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(64,64,1), name=\"Conv1_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling1_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(64, (2,2), activation='relu', name=\"Conv2_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling2_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu', name=\"Conv3_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling3_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3,3), activation='relu', name=\"Conv4_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling4_Layer\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(1024,)))\n",
        "model.add(layers.Dense(512, activation='relu', name=\"Dense_Hidden_Layer1\"))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"Dense_Hidden_Layer2\"))\n",
        "model.add(layers.Dense(128, activation='relu', name=\"Dense_Hidden_Layer3\"))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "model.summary() # Muestra la estructura de la red"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqD9ljII_bwo",
        "colab_type": "text"
      },
      "source": [
        "EXPERIMENTOS CON DROPOUT (DESCOMENTAR EL QUE PROCEDA)\n",
        "\n",
        "*   Dropout de tipo 1: Se usó una probabilidad de de activación de neuronas del 80% en las capas convolucionales (que se representa aquí con un 20% de neuronas desactivadas), mientras que para las capas densas se usó una probabilidad de activación de solamente el 30% (representado por el 70% en el código en Keras)\n",
        "*   Dropout de tipo 2: Es como el tipo 1 pero se pusieron las capas densas con una probabilidad de activación de neuronas del 50%, mientras que en las capas convolucionales se puso una probabilidad de activación del 75% (25% de desactivación) respecto al tipo 1 donde era del 80%.\n",
        "*   Dropout de tipo 3: Las probabilidades usadas son como las del tipo 2, con la diferencia de que ahora no se hace Dropout entre la última capa oculta de la etapa densamente conectada y la capa de salida Softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SZ_qSqZLAjvx",
        "colab": {}
      },
      "source": [
        "############# Código principal de red convolucional ####################################\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "# Experimentos de Dropout: \n",
        "# En Keras, el parámetro de probabilidad que maneja el Dropout indica el \n",
        "# porcentaje de neuronas que quedan desactivadas de manera aleatoria en cada época de entrenamiento. \n",
        "\n",
        "\n",
        "#####################\n",
        "#     DROPOUT 1     #\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(64,64,1), name=\"Conv1_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling1_Layer\"))\n",
        "model.add(layers.Dropout(0.20, name=\"Dropout1_CNN_Layer\")) \n",
        "model.add(layers.Conv2D(64, (2,2), activation='relu', name=\"Conv2_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling2_Layer\"))\n",
        "model.add(layers.Dropout(0.20, name=\"Dropout2_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu', name=\"Conv3_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling3_Layer\"))\n",
        "model.add(layers.Dropout(0.20, name=\"Dropout3_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(256, (3,3), activation='relu', name=\"Conv4_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling4_Layer\"))\n",
        "model.add(layers.Dropout(0.20, name=\"Dropout4_CNN_Layer\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(1024,)))\n",
        "model.add(layers.Dropout(0.7, name=\"Dropout1_Dense_Layer\"))\n",
        "model.add(layers.Dense(512, activation='relu', name=\"Dense_Hidden_Layer1\"))\n",
        "model.add(layers.Dropout(0.7, name=\"Dropout2_Dense_Layer\"))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"Dense_Hidden_Layer2\"))\n",
        "model.add(layers.Dropout(0.7, name=\"Dropout3_Dense_Layer\"))\n",
        "model.add(layers.Dense(128, activation='relu', name=\"Dense_Hidden_Layer3\"))\n",
        "model.add(layers.Dropout(0.7, name=\"Dropout4_Dense_Layer\"))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#####################\n",
        "\n",
        "\"\"\"\n",
        "#####################\n",
        "#     DROPOUT 2     #\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(64,64,1), name=\"Conv1_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling1_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout1_CNN_Layer\")) \n",
        "model.add(layers.Conv2D(64, (2,2), activation='relu', name=\"Conv2_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling2_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout2_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu', name=\"Conv3_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling3_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout3_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(256, (3,3), activation='relu', name=\"Conv4_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling4_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout4_CNN_Layer\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(1024,)))\n",
        "model.add(layers.Dropout(0.5, name=\"Dropout1_Dense_Layer\"))\n",
        "model.add(layers.Dense(512, activation='relu', name=\"Dense_Hidden_Layer1\"))\n",
        "model.add(layers.Dropout(0.5, name=\"Dropout2_Dense_Layer\"))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"Dense_Hidden_Layer2\"))\n",
        "model.add(layers.Dropout(0.5, name=\"Dropout3_Dense_Layer\"))\n",
        "model.add(layers.Dense(128, activation='relu', name=\"Dense_Hidden_Layer3\"))\n",
        "model.add(layers.Dropout(0.5, name=\"Dropout4_Dense_Layer\"))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#####################\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "#####################\n",
        "#     DROPOUT 3     #\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(64,64,1), name=\"Conv1_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling1_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout1_CNN_Layer\")) \n",
        "model.add(layers.Conv2D(64, (2,2), activation='relu', name=\"Conv2_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling2_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout2_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu', name=\"Conv3_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling3_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout3_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(256, (3,3), activation='relu', name=\"Conv4_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling4_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout4_CNN_Layer\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(1024,)))\n",
        "model.add(layers.Dropout(0.5, name=\"Dropout1_Dense_Layer\"))\n",
        "model.add(layers.Dense(512, activation='relu', name=\"Dense_Hidden_Layer1\"))\n",
        "model.add(layers.Dropout(0.5, name=\"Dropout2_Dense_Layer\"))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"Dense_Hidden_Layer2\"))\n",
        "model.add(layers.Dropout(0.5, name=\"Dropout3_Dense_Layer\"))\n",
        "model.add(layers.Dense(128, activation='relu', name=\"Dense_Hidden_Layer3\"))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "#####################\n",
        "\"\"\"\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob__K5qO_d3Y",
        "colab_type": "text"
      },
      "source": [
        "EXPERIMENTOS DE MODIFICACIÓN DE LA RED ORIGINAL (DESCOMENTAR EL QUE PROCEDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdnSOvKDGcun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############# Código principal de red convolucional ####################################\n",
        "# Diseñamos la red:\n",
        "from keras import layers\n",
        "from keras import models\n",
        "# Parametros en cada capa = Nº filtros*(Area filtro + 1). Por ejemplo:\n",
        "# model.add(layers.Conv2D(32,(6,6),activation='relu', input_shape=(32,32,1))) ===> 32*(6*6 + 1) = 1184\n",
        "\n",
        "##########################\n",
        "#     MODIFICACIÓN 1     #\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu', input_shape=(64,64,1), name=\"Conv1_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling1_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(128, (2,2), activation='relu', name=\"Conv2_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling2_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3,3), activation='relu', name=\"Conv3_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling3_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3,3), activation='relu', name=\"Conv4_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling4_Layer\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(2048, activation='relu', input_shape=(2048,)))\n",
        "model.add(layers.Dense(1024, activation='relu', name=\"Dense_Hidden_Layer1\"))\n",
        "model.add(layers.Dense(512, activation='relu', name=\"Dense_Hidden_Layer2\"))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"Dense_Hidden_Layer3\"))\n",
        "model.add(layers.Dense(128, activation='relu', name=\"Dense_Hidden_Layer4\"))\n",
        "model.add(layers.Dense(64, activation='relu', name=\"Dense_Hidden_Layer5\"))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "##########################\n",
        "\n",
        "\"\"\"\n",
        "##########################\n",
        "#     MODIFICACIÓN 2     #\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(16,(3,3),activation='relu', input_shape=(64,64,1), name=\"Conv1_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling1_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(32, (2,2), activation='relu', name=\"Conv2_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling2_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu', name=\"Conv3_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling3_Layer\"))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3,3), activation='relu', name=\"Conv4_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling4_Layer\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(512,)))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"Dense_Hidden_Layer1\"))\n",
        "model.add(layers.Dense(128, activation='relu', name=\"Dense_Hidden_Layer2\"))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "##########################\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "##########################\n",
        "#     MODIFICACIÓN 3     #\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu', input_shape=(64,64,1), name=\"Conv1_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling1_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout1_CNN_Layer\")) \n",
        "model.add(layers.Conv2D(128, (2,2), activation='relu', name=\"Conv2_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling2_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout2_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(256, (3,3), activation='relu', name=\"Conv3_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling3_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout3_CNN_Layer\"))\n",
        "model.add(layers.Conv2D(512, (3,3), activation='relu', name=\"Conv4_Layer\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), name=\"Pooling4_Layer\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout4_CNN_Layer\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(2048, activation='relu', input_shape=(2048,)))\n",
        "model.add(layers.Dense(4096, activation='relu', name=\"Dense_Hidden_Layer1\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout1_Dense_Layer\"))\n",
        "model.add(layers.Dense(2048, activation='relu', name=\"Dense_Hidden_Layer2\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout2_Dense_Layer\"))\n",
        "model.add(layers.Dense(1024, activation='relu', name=\"Dense_Hidden_Layer3\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout3_Dense_Layer\"))\n",
        "model.add(layers.Dense(512, activation='relu', name=\"Dense_Hidden_Layer4\"))\n",
        "model.add(layers.Dropout(0.25, name=\"Dropout4_Dense_Layer\"))\n",
        "model.add(layers.Dense(256, activation='relu', name=\"Dense_Hidden_Layer5\"))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "\n",
        "##########################\n",
        "\"\"\"\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtnBQPhQgWT3",
        "colab_type": "text"
      },
      "source": [
        " ENTRENAMIENTO Y VALIDACIÓN:\n",
        "\n",
        "Se harán varios experimentos, usando en cada uno un optimizador diferente:\n",
        "- SGD\n",
        "- RMSprop\n",
        "- Adam\n",
        "\n",
        "Hay que descomentar el que se desee probar, y definir en cada uno el número épocas y el batch de imágenes deseado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCf0qOGoGvHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Entrenamiento de la red:\n",
        "\n",
        "###############\n",
        "#     SGD     #\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])\n",
        "batch = 200\n",
        "epocas = 250\n",
        "###############\n",
        "\n",
        "\"\"\"\n",
        "###################\n",
        "#     RMSprop     #\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='RMSprop',\n",
        "              metrics=['accuracy'])\n",
        "batch = 200\n",
        "epocas = 50\n",
        "###################\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "################\n",
        "#     Adam     #\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "batch = 200\n",
        "epocas = 50\n",
        "################\n",
        "\"\"\"\n",
        "\n",
        "# Entrenamiento y validación del modelo con el optimizador y métricas elegidas:\n",
        "\n",
        "snn = model.fit(new_train, \n",
        "                train_lab, \n",
        "                batch_size=batch, \n",
        "                epochs=epocas, \n",
        "                validation_data=(new_validation, valid_lab), \n",
        "                shuffle=True, \n",
        "                verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duxCW8J_HPaJ",
        "colab_type": "text"
      },
      "source": [
        "ANÁLISIS DE RESULTADOS DE ENTRENAMIENTO Y VALIDACIÓN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CvvmsWwHGhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para pintar gráficas de accuracy:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(snn.history['accuracy'],'r')  \n",
        "plt.plot(snn.history['val_accuracy'],'g')  \n",
        "plt.rcParams['figure.figsize'] = (20, 10)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.xlabel(\"Num of Epochs\")  \n",
        "plt.ylabel(\"Accuracy\")  \n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")  \n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.grid(True)\n",
        "plt.savefig(\"Train_acc_vs_Val_acc.jpg\", bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYjGLUUued9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para pintar gráficas de loss:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure() \n",
        "plt.plot(snn.history['loss'],'r')  \n",
        "plt.plot(snn.history['val_loss'],'g')\n",
        "plt.rcParams['figure.figsize'] = (20, 10)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.xlabel(\"Num of Epochs\")  \n",
        "plt.ylabel(\"Loss\")  \n",
        "plt.title(\"Training Loss vs Validation Loss\")  \n",
        "plt.legend(['train','validation'])\n",
        "plt.grid(True)\n",
        "plt.savefig(\"Train_loss_vs_Val_loss.jpg\", bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCcDsdlcHZvZ",
        "colab_type": "text"
      },
      "source": [
        "ANÁLISIS DE TEST:\n",
        "\n",
        "Se obtendrá el accuracy de test del modelo entrenado, la matriz de confusión, y las métricas de precisió, recall y F1 para cada clase del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBh1AAj2VEer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc= model.evaluate(test, test_labels)\n",
        "print (\"Test Accuracy:\", test_acc)\n",
        "print (\"Test Loss:\", test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5tMqIqIHdDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b800ed45-0c16-4110-8026-4615cc6ab41b"
      },
      "source": [
        "# Generación de predicciones (o TEST): Le damos imágenes sin las etiquetas, diferentes a las usadas ya, y a ver que sale:\n",
        "# Se comprueba antes de hacer la predicción:\n",
        "#plt.imshow(x_test[11], cmap=plt.cm.binary) # Es un '6'\n",
        "# Ahora se hace la predicción y se mira si coincide con lo que debe salir:\n",
        "#predictions = model.predict(np.array(test), batch_size=32, verbose=1)\n",
        "predictions = model.predict(test, batch_size=batch, verbose=1)\n",
        "pred_max = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Matriz de confusión:\n",
        "conf_matrix = confusion_matrix(np.argmax(test_labels, axis=1), pred_max)\n",
        "# Se visualiza:\n",
        "import pandas as pd\n",
        "show_matrix = pd.DataFrame(conf_matrix, range(43), range(43))\n",
        "show_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 4ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awCQWNjXHnbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultados = classification_report(np.argmax(test_labels, axis=1), pred_max)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szRJakj0rXbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Se imprimen por un txt y luego se sacan por pantalla:\n",
        "\n",
        "import sys\n",
        "orig_stdout = sys.stdout # Guarda la dirección actual de escritura\n",
        "sys.stdout = open('Test.txt','wt') # Cambia la salida de datos al archivo.txt\n",
        "print(resultados) # Imprime en el archivo.txt\n",
        "\n",
        "sys.stdout.close() # Se cierra el archivo\n",
        "sys.stdout=orig_stdout # Se retorna la salida de datos aquí\"\"\"\n",
        "print(resultados) # Escribe aquí en la celda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nhpY-1yHq9n",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, se guardan la estructura y los pesos de la red obtenida,dándole el nombre deseado. En este caso, se le da un nombre con los accuracy de los 3 análisis, el optimizador empleado, el número de épocas, y el número de imágenes en el batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjrNpTYFHtFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "455e1ef3-6887-42ca-d338-17beca044cda"
      },
      "source": [
        "# Guardar el modelo de red:\n",
        "# Nombre del archivo:\n",
        "nombre = \"Tr_100%_Val_99_10%_Te_92_87%_Adam_50epoch_200batch\"\n",
        "# serializar el modelo a JSON\n",
        "model_json = model.to_json()\n",
        "with open(nombre + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serializar los pesos a HDF5\n",
        "model.save_weights(nombre + \".h5\")\n",
        "print(\"Modelo Guardado!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo Guardado!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}